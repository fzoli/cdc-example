name: cdc-playground

volumes:
  postgres_data: {}
  zoo1_data: {}
  kafka1_data: {}

services:

  postgres:
    restart: always
    image: postgres:16
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: cdc
    ports:
      - "127.0.0.1:5432:5432" # binding to localhost is important in case of weak password; see https://github.com/docker-library/postgres/issues/1054
    volumes:
      - postgres_data:/var/lib/postgresql/data
    command: >
      postgres -c wal_level=logical
               -c max_wal_senders=10
               -c max_replication_slots=10
               -c wal_keep_size=64
               -c wal_compression=on
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 3s
      retries: 5

  connect:
    restart: always
    image: debezium/connect:3.0.0.Final
    container_name: connect
    depends_on:
      - kafka1
#      - schema-registry
      - postgres
    ports:
      - "127.0.0.1:8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka1:19092
      GROUP_ID: debezium-connect
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-status
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_PLUGIN_PATH: /kafka/connect,/debezium-connector
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_LOG4J_LOGGERS: org.reflections=ERROR

#  schema-registry: # only for io.confluent.connect.avro.AvroConverter
#    restart: always
#    image: confluentinc/cp-schema-registry:7.8.0
#    environment:
#      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka1:19092"
#      SCHEMA_REGISTRY_HOST_NAME: schema-registry
#    ports:
#      - "127.0.0.1:8081:8081"

  zoo1:
    restart: always
    image: confluentinc/cp-zookeeper:7.8.0
    hostname: zoo1
    container_name: zoo1
    ports:
      - "127.0.0.1:2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888
    volumes:
      - zoo1_data:/var/lib/zookeeper/data

  kafka1:
    restart: always
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka1
    container_name: kafka1
    ports:
      - "127.0.0.1:9092:9092"
      - "127.0.0.1:29092:29092"
      - "127.0.0.1:9999:9999"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    volumes:
      - kafka1_data:/var/lib/kafka/data
    depends_on:
      - zoo1
